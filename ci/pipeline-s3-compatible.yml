# Concourse Pipeline for GitHub Release Monitor - S3-Compatible Version
# This pipeline supports both AWS S3 and S3-compatible storage (Minio, etc.)

resources:
  - name: release-monitor-repo
    type: git
    source:
      uri: ((git_repo_uri))
      branch: ((git_branch))
      private_key: ((git_private_key))

  - name: schedule-trigger
    type: time
    source:
      interval: 1h  # Check every hour

  - name: monitor-output
    type: s3
    source:
      # S3-compatible endpoint (leave empty for AWS S3)
      endpoint: ((s3_endpoint))
      
      # Standard S3 configuration
      bucket: ((s3_bucket))
      region_name: ((s3_region))
      access_key_id: ((s3_access_key))
      secret_access_key: ((s3_secret_key))
      
      # S3-compatible options
      # disable_ssl: ((s3_disable_ssl))
      skip_ssl_verification: ((s3_skip_ssl_verification))
      # use_v4: ((s3_use_v4))  # Required for Minio
      
      # File configuration
      versioned_file: release-monitor/latest-releases.json


jobs:
  - name: monitor-releases
    plan:
      - in_parallel:
          - get: release-monitor-repo
          - get: schedule-trigger
            trigger: true

      - task: check-releases
        file: release-monitor-repo/ci/tasks/check-releases/task.yml
        params:
          GITHUB_TOKEN: ((github_token))
          # Pass S3-compatible endpoint to task if needed
          S3_ENDPOINT: ((s3_endpoint))

      - put: monitor-output
        params:
          file: release-output/releases.json
          content_type: application/json

  - name: download-new-releases
    plan:
      - in_parallel:
          - get: release-monitor-repo
          - get: monitor-output
            trigger: true
            passed: [monitor-releases]

      - task: download-releases
        file: release-monitor-repo/ci/tasks/download-releases/task.yml
        input_mapping:
          release-monitor: release-monitor-repo
          monitor-output: monitor-output
        params:
          GITHUB_TOKEN: ((github_token))
          ASSET_PATTERNS: ((download_asset_patterns))
          INCLUDE_PRERELEASES: ((download_include_prereleases))
          VERIFY_DOWNLOADS: ((download_verify_downloads))
          CLEANUP_OLD_VERSIONS: ((download_cleanup_old_versions))
          KEEP_VERSIONS: ((download_keep_versions))
          REPOSITORY_OVERRIDES: ((download_repository_overrides))
          
          # S3 version database configuration
          USE_S3_VERSION_DB: ((use_s3_version_db))
          VERSION_DB_S3_BUCKET: ((version_db_s3_bucket))
          VERSION_DB_S3_PREFIX: ((version_db_s3_prefix))
          VERSION_DB_S3_REGION: ((s3_region))
          AWS_ACCESS_KEY_ID: ((s3_access_key))
          AWS_SECRET_ACCESS_KEY: ((s3_secret_key))
          
          # S3-compatible endpoint for version DB
          S3_ENDPOINT: ((s3_endpoint))
          
          # Force re-download for testing (comment out in production)
          # FORCE_DOWNLOAD: "true"

      # Upload downloaded files to S3 storage
      - task: upload-to-s3
        config:
          platform: linux
          image_resource:
            type: registry-image
            source:
              repository: python
              tag: 3.9-slim
          inputs:
            - name: downloads
          params:
            AWS_ACCESS_KEY_ID: ((s3_access_key))
            AWS_SECRET_ACCESS_KEY: ((s3_secret_key))
            AWS_DEFAULT_REGION: ((s3_region))
            S3_ENDPOINT: ((s3_endpoint))
            S3_BUCKET: ((s3_releases_bucket))
          run:
            path: bash
            args:
              - -exc
              - |
                # Install boto3 first
                pip3 install --quiet boto3
                
                # Run the upload script
                python3 -c "
                import os
                import boto3
                from pathlib import Path
                
                # Configure S3 client
                endpoint_url = os.environ.get('S3_ENDPOINT')
                s3_kwargs = {
                    'region_name': os.environ.get('AWS_DEFAULT_REGION', 'us-east-1')
                }
                
                if endpoint_url:
                    s3_kwargs['endpoint_url'] = endpoint_url
                    print(f'Using S3-compatible endpoint: {endpoint_url}')
                
                s3 = boto3.client('s3', **s3_kwargs)
                bucket = os.environ['S3_BUCKET']
                
                # Find and upload all release files
                downloads_dir = Path('downloads')
                if not downloads_dir.exists():
                    print(f'ERROR: {downloads_dir} does not exist!')
                    exit(1)
                    
                uploaded_count = 0
                
                for file_path in downloads_dir.rglob('*'):
                    if file_path.is_file() and (file_path.suffix in ['.gz', '.zip']):
                        # Create S3 key maintaining directory structure
                        relative_path = file_path.relative_to(downloads_dir)
                        s3_key = f'release-downloads/{relative_path}'
                        
                        print(f'Uploading {relative_path} to s3://{bucket}/{s3_key}')
                        
                        try:
                            with open(file_path, 'rb') as f:
                                s3.put_object(Bucket=bucket, Key=s3_key, Body=f)
                            uploaded_count += 1
                            print(f'  Success: Uploaded {file_path.stat().st_size} bytes')
                        except Exception as e:
                            print(f'Error uploading {file_path}: {e}')
                            raise
                
                if uploaded_count == 0:
                    print('\\nINFO: No release files found to upload.')
                    print('This is normal when all monitored releases are already at their latest versions.')
                    
                    # Show what files were found for debugging
                    file_count = sum(1 for p in downloads_dir.rglob('*') if p.is_file())
                    if file_count > 0:
                        print(f'\\nFound {file_count} metadata files in downloads directory.')
                else:
                    print(f'\\nSUCCESS: Uploaded {uploaded_count} files to S3.')
                "

  - name: cleanup-old-releases
    plan:
      - in_parallel:
          - get: release-monitor-repo
          - get: schedule-trigger
            trigger: true

      - task: cleanup-releases
        file: release-monitor-repo/ci/tasks/download-tarballs/task.yml
        params:
          CLEANUP_MODE: "true"
          DAYS_TO_KEEP: ((cleanup_days_to_keep))
          # Pass S3-compatible configuration
          S3_ENDPOINT: ((s3_endpoint))
          AWS_ACCESS_KEY_ID: ((s3_access_key))
          AWS_SECRET_ACCESS_KEY: ((s3_secret_key))

  # Test job to force re-download of a specific release
  - name: test-download-with-upload
    plan:
      - get: release-monitor-repo
      
      - task: create-test-monitor-output
        config:
          platform: linux
          image_resource:
            type: registry-image
            source:
              repository: busybox
          outputs:
            - name: monitor-output
              path: /tmp/monitor-output
          run:
            path: sh
            args:
              - -exc
              - |
                # Create a test monitor output with one small release to download
                cat > /tmp/monitor-output/latest-releases.json << 'EOF'
                {
                  "timestamp": 1234567890,
                  "total_repositories_checked": 1,
                  "new_releases_found": 1,
                  "releases": [
                    {
                      "repository": "malston/release-monitor",
                      "owner": "malston",
                      "repo": "release-monitor",
                      "tag_name": "v1.0.0",
                      "name": "Release v1.0.0",
                      "published_at": "2024-01-01T00:00:00Z",
                      "html_url": "https://github.com/malston/release-monitor/releases/tag/v1.0.0",
                      "assets_url": "https://api.github.com/repos/malston/release-monitor/releases/12345/assets",
                      "body": "Test release"
                    }
                  ]
                }
                EOF
                
                echo "Created test monitor output"
                
      - task: download-releases
        file: release-monitor-repo/ci/tasks/download-releases/task.yml
        input_mapping:
          release-monitor: release-monitor-repo
          monitor-output: monitor-output
        params:
          GITHUB_TOKEN: ((github_token))
          ASSET_PATTERNS: ((download_asset_patterns))
          INCLUDE_PRERELEASES: ((download_include_prereleases))
          VERIFY_DOWNLOADS: ((download_verify_downloads))
          CLEANUP_OLD_VERSIONS: ((download_cleanup_old_versions))
          KEEP_VERSIONS: ((download_keep_versions))
          REPOSITORY_OVERRIDES: ((download_repository_overrides))
          
          # S3 version database configuration
          USE_S3_VERSION_DB: ((use_s3_version_db))
          VERSION_DB_S3_BUCKET: ((version_db_s3_bucket))
          VERSION_DB_S3_PREFIX: test-version-db/  # Use separate prefix for testing
          VERSION_DB_S3_REGION: ((s3_region))
          AWS_ACCESS_KEY_ID: ((s3_access_key))
          AWS_SECRET_ACCESS_KEY: ((s3_secret_key))
          
          # S3-compatible endpoint for version DB
          S3_ENDPOINT: ((s3_endpoint))
      
      - task: upload-to-s3
        config:
          platform: linux
          image_resource:
            type: registry-image
            source:
              repository: python
              tag: 3.9-slim
          inputs:
            - name: downloads
          params:
            AWS_ACCESS_KEY_ID: ((s3_access_key))
            AWS_SECRET_ACCESS_KEY: ((s3_secret_key))
            AWS_DEFAULT_REGION: ((s3_region))
            S3_ENDPOINT: ((s3_endpoint))
            S3_BUCKET: ((s3_releases_bucket))
          run:
            path: bash
            args:
              - -exc
              - |
                # Install boto3 first
                pip3 install --quiet boto3
                
                # Run the upload script
                python3 -c "
                import os
                import boto3
                from pathlib import Path
                
                # Configure S3 client
                endpoint_url = os.environ.get('S3_ENDPOINT')
                s3_kwargs = {
                    'region_name': os.environ.get('AWS_DEFAULT_REGION', 'us-east-1')
                }
                
                if endpoint_url:
                    s3_kwargs['endpoint_url'] = endpoint_url
                    print(f'Using S3-compatible endpoint: {endpoint_url}')
                
                s3 = boto3.client('s3', **s3_kwargs)
                bucket = os.environ['S3_BUCKET']
                
                # Find and upload all release files
                downloads_dir = Path('downloads')
                if not downloads_dir.exists():
                    print(f'ERROR: {downloads_dir} does not exist!')
                    exit(1)
                    
                uploaded_count = 0
                
                for file_path in downloads_dir.rglob('*'):
                    if file_path.is_file() and (file_path.suffix in ['.gz', '.zip']):
                        # Create S3 key maintaining directory structure
                        relative_path = file_path.relative_to(downloads_dir)
                        s3_key = f'release-downloads/{relative_path}'
                        
                        print(f'Uploading {relative_path} to s3://{bucket}/{s3_key}')
                        
                        try:
                            with open(file_path, 'rb') as f:
                                s3.put_object(Bucket=bucket, Key=s3_key, Body=f)
                            uploaded_count += 1
                            print(f'  Success: Uploaded {file_path.stat().st_size} bytes')
                        except Exception as e:
                            print(f'Error uploading {file_path}: {e}')
                            raise
                
                if uploaded_count == 0:
                    print('\\nINFO: No release files found to upload.')
                    print('This is normal when all monitored releases are already at their latest versions.')
                    
                    # Show what files were found for debugging
                    file_count = sum(1 for p in downloads_dir.rglob('*') if p.is_file())
                    if file_count > 0:
                        print(f'\\nFound {file_count} metadata files in downloads directory.')
                else:
                    print(f'\\nSUCCESS: Uploaded {uploaded_count} files to S3.')
                "

# Resource types (if not available in your Concourse deployment)
resource_types:
  - name: s3
    type: registry-image
    source:
      repository: concourse/s3-resource
      tag: 1.2.1  # Use specific version that supports endpoints